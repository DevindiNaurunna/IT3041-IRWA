{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95a43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Build IT Lecture Knowledge Base (KB)\n",
    "# \n",
    "# Steps:\n",
    "# 1. Load seed IT lecture dataset (JSONL)\n",
    "# 2. Chunk transcripts into small pieces\n",
    "# 3. Generate embeddings (Gemini API if available, else Sentence Transformers)\n",
    "# 4. Save chunks + embeddings + metadata for retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e277ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% imports\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40506b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% paths\n",
    "KB_DIR = Path(\"../data/kb\")\n",
    "KB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = KB_DIR / \"it_lectures_seed.jsonl\"   # raw dataset\n",
    "CHUNKS = KB_DIR / \"kb_chunks.jsonl\"        # processed chunks\n",
    "EMB_FILE = KB_DIR / \"kb_embeddings.npy\"    # embedding matrix\n",
    "META = KB_DIR / \"kb_meta.json\"             # metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "712888ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% helper: chunker\n",
    "def chunk_text(text: str, max_words: int = 120):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), max_words):\n",
    "        piece = \" \".join(words[i:i+max_words]).strip()\n",
    "        if piece:\n",
    "            chunks.append(piece)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15a0a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>course</th>\n",
       "      <th>topic_tags</th>\n",
       "      <th>transcript</th>\n",
       "      <th>gold_outline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ml_basics_01</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>[supervised, unsupervised, reinforcement]</td>\n",
       "      <td>Machine learning is about learning patterns fr...</td>\n",
       "      <td>{'title': 'ML Basics', 'topics': ['Supervised'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>db_norm_01</td>\n",
       "      <td>Databases</td>\n",
       "      <td>[normalization, 1NF, 2NF, 3NF]</td>\n",
       "      <td>Database normalization organizes data to reduc...</td>\n",
       "      <td>{'title': 'Database Normalization', 'topics': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>net_funda_01</td>\n",
       "      <td>Networking</td>\n",
       "      <td>[OSI, TCP/IP, routing]</td>\n",
       "      <td>The OSI model has seven layers from physical u...</td>\n",
       "      <td>{'title': 'Networking Fundamentals', 'topics':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id            course                                 topic_tags  \\\n",
       "0  ml_basics_01  Machine Learning  [supervised, unsupervised, reinforcement]   \n",
       "1    db_norm_01         Databases             [normalization, 1NF, 2NF, 3NF]   \n",
       "2  net_funda_01        Networking                     [OSI, TCP/IP, routing]   \n",
       "\n",
       "                                          transcript  \\\n",
       "0  Machine learning is about learning patterns fr...   \n",
       "1  Database normalization organizes data to reduc...   \n",
       "2  The OSI model has seven layers from physical u...   \n",
       "\n",
       "                                        gold_outline  \n",
       "0  {'title': 'ML Basics', 'topics': ['Supervised'...  \n",
       "1  {'title': 'Database Normalization', 'topics': ...  \n",
       "2  {'title': 'Networking Fundamentals', 'topics':...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% load seed data\n",
    "rows = []\n",
    "with open(SEED, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rows.append(json.loads(line))\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bedf42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 3\n"
     ]
    }
   ],
   "source": [
    "# %% chunk transcripts\n",
    "chunk_rows = []\n",
    "for r in rows:\n",
    "    chunks = chunk_text(r[\"transcript\"], max_words=120)\n",
    "    for j, ch in enumerate(chunks):\n",
    "        chunk_rows.append({\n",
    "            \"id\": f'{r[\"id\"]}_c{j}',\n",
    "            \"parent_id\": r[\"id\"],\n",
    "            \"course\": r[\"course\"],\n",
    "            \"topic_tags\": r[\"topic_tags\"],\n",
    "            \"text\": ch\n",
    "        })\n",
    "\n",
    "print(\"Total chunks:\", len(chunk_rows))\n",
    "\n",
    "# save chunks\n",
    "with open(CHUNKS, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in chunk_rows:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "400a87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (3, 768) (rows × dim)\n"
     ]
    }
   ],
   "source": [
    "# %% embeddings (corrected)\n",
    "USE_GEMINI = bool(os.getenv(\"GEMINI_API_KEY\"))\n",
    "D = 0  # will set after embedding\n",
    "\n",
    "if USE_GEMINI:\n",
    "    from google import genai\n",
    "    client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "    texts = [r[\"text\"] for r in chunk_rows]\n",
    "\n",
    "    vectors = []\n",
    "    BATCH_SIZE = 32  # batch to avoid timeouts\n",
    "\n",
    "    for i in range(0, len(texts), BATCH_SIZE):\n",
    "        batch = texts[i : i + BATCH_SIZE]\n",
    "        # The new GenAI SDK expects \"contents\" as list\n",
    "        resp = client.models.embed_content(\n",
    "            model=\"text-embedding-004\",\n",
    "            contents=batch\n",
    "        )\n",
    "        # resp.embeddings is a list of objects with `.values`\n",
    "        for emb in resp.embeddings:\n",
    "            vec = np.array(emb.values, dtype=\"float32\")\n",
    "            vectors.append(vec)\n",
    "\n",
    "    E = np.vstack(vectors)\n",
    "    D = E.shape[1]\n",
    "else:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    texts = [r[\"text\"] for r in chunk_rows]\n",
    "    E = model.encode(texts, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
    "    D = E.shape[1]\n",
    "\n",
    "# Save embeddings matrix\n",
    "np.save(EMB_FILE, E)\n",
    "\n",
    "# Optionally display vector shape\n",
    "print(f\"Embeddings shape: {E.shape} (rows × dim)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18db3c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KB built\n",
      " - ..\\data\\kb\\kb_chunks.jsonl\n",
      " - ..\\data\\kb\\kb_embeddings.npy\n",
      " - ..\\data\\kb\\kb_meta.json\n"
     ]
    }
   ],
   "source": [
    "# %% save metadata\n",
    "meta = {\n",
    "    \"model\": \"text-embedding-004\" if USE_GEMINI else \"all-MiniLM-L6-v2\",\n",
    "    \"dim\": int(D),\n",
    "    \"rows\": int(E.shape[0]),\n",
    "}\n",
    "with open(META, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"✅ KB built\")\n",
    "print(\" -\", CHUNKS)\n",
    "print(\" -\", EMB_FILE)\n",
    "print(\" -\", META)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
